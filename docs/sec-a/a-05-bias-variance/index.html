<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.63">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous"><title data-react-helmet="true">Bias and Variance Dilemma &amp; Shrinkage Methods | MIS 382N: Advaned Predictive Modelling</title><meta data-react-helmet="true" name="docsearch:version" content="current"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:title" content="Bias and Variance Dilemma &amp; Shrinkage Methods | MIS 382N: Advaned Predictive Modelling"><meta data-react-helmet="true" name="description" content="Authors: Jing Fang, Andrew Han, Hao He. (PDF)"><meta data-react-helmet="true" property="og:description" content="Authors: Jing Fang, Andrew Han, Hao He. (PDF)"><meta data-react-helmet="true" property="og:url" content="https://ideal-ut.github.io/APM-2020/docs/sec-a/a-05-bias-variance"><link data-react-helmet="true" rel="shortcut icon" href="/APM-2020/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://ideal-ut.github.io/APM-2020/docs/sec-a/a-05-bias-variance"><link rel="stylesheet" href="/APM-2020/styles.12cdeefe.css">
<link rel="preload" href="/APM-2020/styles.2cffed3b.js" as="script">
<link rel="preload" href="/APM-2020/runtime~main.47f4a8e7.js" as="script">
<link rel="preload" href="/APM-2020/main.2d013a91.js" as="script">
<link rel="preload" href="/APM-2020/1.1bd411a9.js" as="script">
<link rel="preload" href="/APM-2020/2.a2e25927.js" as="script">
<link rel="preload" href="/APM-2020/32.9618ee48.js" as="script">
<link rel="preload" href="/APM-2020/f976f453.84bb295e.js" as="script">
<link rel="preload" href="/APM-2020/17896441.32dbdef4.js" as="script">
<link rel="preload" href="/APM-2020/3d264858.47e169e0.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav class="navbar navbar--light navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/APM-2020/"><strong class="navbar__title"></strong></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/APM-2020/docs/">Home</a></div><div class="navbar__items navbar__items--right"><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2aTZ"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_BsTx">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_BsTx">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/APM-2020/"><strong class="navbar__title"></strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/APM-2020/docs/">Home</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_2gpo"><div class="docSidebarContainer_3_JD" role="complementary"><div class="sidebar_2urC"><div class="menu menu--responsive menu_5FrY"><button aria-label="Open Menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_Dm3K" xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 32 32" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/APM-2020/docs/">Info</a></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Section A</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-01-gaussian-dist">The Gaussian Distribution</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-02-mlr">Multiple Linear Regression</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-03-parametric-models">Parametric Models</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-04-regularization">Regularization</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/APM-2020/docs/sec-a/a-05-bias-variance">Bias and Variance Dilemma &amp; Shrinkage Methods</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-06-gradient-descent">Gradient Descent</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-07-sgd">Stochastic Gradient Descent (SGD) &amp; Neural Network Intro.</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-08-nn">Neural Networks</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-09-mlp">Multi-Layered Perceptron</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-10-dp">Data Preprocessing</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-11-outliers">Handling Outliers</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/APM-2020/docs/sec-a/a-12-reducing-features">Reducing the Number of (Derived) Attributes/Features.</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Section B</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-01-gaussian-dist">The Gaussian Distribution</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-02-mlr">Multiple Linear Regression</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-03-parametric-models">Function approximation (Regression)</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-04-regularization">Regularization</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-05-bias-variance">Bias-Variance Dilemma</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-06-gradient-descent">Beyond Linear Regression and Gradient Descent</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-07-sgd">Stochastic Gradient Decent</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-08-nn">Neural Networks</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-09-mlp">Multi-Layered Perceptron</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-10-dp">Data Preprocessing</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-11-outliers">Handling Outliers</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/APM-2020/docs/sec-b/b-12-reducing-features">All About Features</a></li></ul></li></ul></div></div></div><main class="docMainContainer_3EyW"><div class="container padding-vert--lg docItemWrapper_1EkI"><div class="row"><div class="col docItemCol_2ASc"><div class="docItemContainer_3QWW"><article><div><span class="badge badge--secondary">Version: Next</span></div><header><h1 class="docTitle_1Lrw">Bias and Variance Dilemma &amp; Shrinkage Methods</h1></header><div class="markdown"><p>Authors: Jing Fang, Andrew Han, Hao He. (<a target="_blank" href="/APM-2020/assets/files/a-05-bias-variance-b6742f88d53b50510a8b3d4be893a9ee.pdf">PDF</a>)</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="course-content"></a>Course Content<a aria-hidden="true" tabindex="-1" class="hash-link" href="#course-content" title="Direct link to heading">#</a></h2><p>During this week&#x27;s lecture, we discussed about the Bias-Variance dilemma and how the expected loss could be split into reducible and irreducible error. Inside the reducible error, we are able to observe the left term as the bias and the right term as the variance.</p><p>We also revisited Lasso and Ridge specifically comparing the shrinkage methods to see how both models deal with regularization penalties.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="bias-variance-trade-off"></a>Bias-Variance Trade Off<a aria-hidden="true" tabindex="-1" class="hash-link" href="#bias-variance-trade-off" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="the-bias-variance-decomposition"></a>The Bias-Variance Decomposition<a aria-hidden="true" tabindex="-1" class="hash-link" href="#the-bias-variance-decomposition" title="Direct link to heading">#</a></h3><p>The expected squared loss is <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">[</mo><mi>L</mi><mo stretchy="false">]</mo><mo>=</mo><mo>âˆ«</mo><mo stretchy="false">{</mo><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>âˆ’</mo><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">}</mo><mn>2</mn></msup><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>d</mi><mi>x</mi><mo>+</mo><mo>âˆ«</mo><mo>âˆ«</mo><mo stretchy="false">{</mo><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>âˆ’</mo><mi>t</mi><msup><mo stretchy="false">}</mo><mn>2</mn></msup><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mi>d</mi><mi>x</mi><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">E[L] = \int \{y(x) - h(x)\}^2p(x)dx + \int \int \{h(x) - t\}^2p(x,t)dxdt</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mopen">[</span><span class="mord mathnormal">L</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.11112em;vertical-align:-0.30612em"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em">âˆ«</span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.11112em;vertical-align:-0.30612em"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em">âˆ«</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em">âˆ«</span><span class="mopen">{</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord mathnormal">t</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span></span></span></p><p>The second term is independent of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>. It arises from the noise on the data and represents the minimum achievable value of the expected loss.</p><p>The first term depends on our choice for the function <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>, and we will seek a solution for <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span> which makes this term a minimum. Suppose we have a data set <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span></span> containing a finite number <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span></span> of data points, then the expected loss is </p><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>D</mi></msub><mo stretchy="false">[</mo><mo stretchy="false">{</mo><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>D</mi><mo stretchy="false">)</mo><mo>âˆ’</mo><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">}</mo><mn>2</mn></msup><mo stretchy="false">]</mo><mo>=</mo><mo stretchy="false">{</mo><msub><mi>E</mi><mi>D</mi></msub><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>D</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>âˆ’</mo><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">}</mo><mn>2</mn></msup><mo>+</mo><msub><mi>E</mi><mi>D</mi></msub><mo stretchy="false">[</mo><mo stretchy="false">{</mo><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>D</mi><mo stretchy="false">)</mo><mo>âˆ’</mo><msub><mi>E</mi><mi>D</mi></msub><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>D</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mo stretchy="false">}</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">E_D[\{y(x;D) - h(x)\}^2] = \{E_D[y(x;D)] - h(x)\}^2 + E_D[\{y(x;D) - E_D[y(x;D)]\}^2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mclose">]</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span> </p><p>It can be expressed as the sum of two terms: </p><ul><li>The first term, called the squared <em>bias</em>, represents the extent to which the average prediction over all data sets differs from the desired regression function. </li><li>The second term, called the <em>variance</em>, measures the extent to which the function <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y(x;D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></span> is sensitive to the particular choice of data set.</li></ul><p>We obtain the decomposition of the expected squared loss
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">x</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">d</mi><mtext>Â </mtext><mi mathvariant="normal">l</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi><mo>=</mo><mo stretchy="false">(</mo><mi mathvariant="normal">b</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">s</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mi mathvariant="normal">v</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">e</mi><mo>+</mo><mi mathvariant="normal">n</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi></mrow><annotation encoding="application/x-tex">\mathrm{ expected\ loss = (bias)^2 + variance + noise }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathrm">e</span><span class="mord mathrm">x</span><span class="mord mathrm">p</span><span class="mord mathrm">e</span><span class="mord mathrm">c</span><span class="mord mathrm">t</span><span class="mord mathrm">e</span><span class="mord mathrm">d</span><span class="mspace">Â </span><span class="mord mathrm">l</span><span class="mord mathrm">o</span><span class="mord mathrm">s</span><span class="mord mathrm">s</span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mopen">(</span><span class="mord mathrm">b</span><span class="mord mathrm">i</span><span class="mord mathrm">a</span><span class="mord mathrm">s</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mord mathrm" style="margin-right:0.01389em">v</span><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm">i</span><span class="mord mathrm">a</span><span class="mord mathrm">n</span><span class="mord mathrm">c</span><span class="mord mathrm">e</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mord mathrm">n</span><span class="mord mathrm">o</span><span class="mord mathrm">i</span><span class="mord mathrm">s</span><span class="mord mathrm">e</span></span></span></span></span></span></p><p>where
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">b</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">s</mi><mo stretchy="false">)</mo></mrow><mn>2</mn></msup><mo>=</mo><mo>âˆ«</mo><mo stretchy="false">{</mo><msub><mi>E</mi><mi>D</mi></msub><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>D</mi><mo stretchy="false">)</mo><mo>âˆ’</mo><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">}</mo><mn>2</mn></msup><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>d</mi><mi>x</mi><mo separator="true">,</mo><mrow><mi mathvariant="normal">v</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">e</mi></mrow><mo>=</mo><mo>âˆ«</mo><msub><mi>E</mi><mi>D</mi></msub><mo stretchy="false">[</mo><mo stretchy="false">{</mo><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>D</mi><mo stretchy="false">)</mo><mo>âˆ’</mo><msub><mi>E</mi><mi>D</mi></msub><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>D</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mo stretchy="false">}</mo><mn>2</mn></msup><mo stretchy="false">]</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>d</mi><mi>x</mi><mo separator="true">,</mo><mrow><mi mathvariant="normal">n</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi></mrow><mo>=</mo><mo>âˆ«</mo><mo>âˆ«</mo><mo stretchy="false">{</mo><mi>h</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>âˆ’</mo><mi>t</mi><msup><mo stretchy="false">}</mo><mn>2</mn></msup><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>t</mi><mo stretchy="false">)</mo><mi>d</mi><mi>x</mi><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\mathrm{(bias)}^2 = \int \{E_D[y(x;D) - h(x)\}^2p(x)dx, \mathrm{variance} = \int E_D[\{y(x;D) - E_D[y(x;D)]\}^2]p(x)dx, \mathrm{noise} = \int\int \{h(x) - t\}^2p(x,t)dxdt</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.204008em;vertical-align:-0.25em"></span><span class="mord"><span class="mord"><span class="mopen">(</span><span class="mord mathrm">b</span><span class="mord mathrm">i</span><span class="mord mathrm">a</span><span class="mord mathrm">s</span><span class="mclose">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.954008em"><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.11112em;vertical-align:-0.30612em"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em">âˆ«</span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord"><span class="mord mathrm" style="margin-right:0.01389em">v</span><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm">i</span><span class="mord mathrm">a</span><span class="mord mathrm">n</span><span class="mord mathrm">c</span><span class="mord mathrm">e</span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.11112em;vertical-align:-0.30612em"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em">âˆ«</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mclose">]</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord"><span class="mord mathrm">n</span><span class="mord mathrm">o</span><span class="mord mathrm">i</span><span class="mord mathrm">s</span><span class="mord mathrm">e</span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.11112em;vertical-align:-0.30612em"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em">âˆ«</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em">âˆ«</span><span class="mopen">{</span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em"></span><span class="mord mathnormal">t</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span></span></span></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="the-bias-variance-tradeoff"></a>The Bias-Variance Tradeoff<a aria-hidden="true" tabindex="-1" class="hash-link" href="#the-bias-variance-tradeoff" title="Direct link to heading">#</a></h3><p>There is a trade-off between bias and variance, with very flexible models having low bias and high variance, and relatively rigid models having high bias and low variance. The model with the optimal predictive capability is the one that leads to the best balance between bias and variance.</p><p><img src="https://miro.medium.com/max/1482/1*WXi_7HIL3FKETFdfegcEmA.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="how-to-improve-model-performance-managing-bias-and-variance"></a>How to Improve Model Performance: Managing Bias and Variance<a aria-hidden="true" tabindex="-1" class="hash-link" href="#how-to-improve-model-performance-managing-bias-and-variance" title="Direct link to heading">#</a></h3><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="1-there-is-no-escaping-the-relationship-between-bias-and-variance-in-machine-learning"></a>1. There is no escaping the relationship between bias and variance in machine learning.<a aria-hidden="true" tabindex="-1" class="hash-link" href="#1-there-is-no-escaping-the-relationship-between-bias-and-variance-in-machine-learning" title="Direct link to heading">#</a></h4><p>Achieving low bias and low variance is the univeral goal of any supervised machine learning models. That is the measurement of the performance of a model. The parameterization of models is often a battle to balance out bias and variance. For example, changing the bundle of m and B values of a Random Forest model adjusts the number of variables used to train every tree in the forest and how many trees in total are there in the forest. Increasing m and B values on the one hand contributes to decreasing model bias by making the model more complex, but on the other hand the more complicated model also increases model variance.  </p><p>In general:</p><ul><li>Increasing the bias will decrease the variance.</li><li>Increasing the variance will decrease the bias.</li></ul><p>There is a trade-off at play between these two concerns and the algorithms you choose and the way you choose to configure them are finding different balances in this trade-off for your problem. However in real life, there is not a quantitative way to find the optimal model from bias-variance trade-off because we do not know the actual underlying target function. Instead we must use an accurate measure of prediction error and explore differing levels of model complexity and then choose the complexity level that minimizes the overall error.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="2-model-complicity-does-not--necessarily-secure-model-performance-in-real-life"></a>2. Model complicity does not  necessarily secure model performance in real life.<a aria-hidden="true" tabindex="-1" class="hash-link" href="#2-model-complicity-does-not--necessarily-secure-model-performance-in-real-life" title="Direct link to heading">#</a></h4><p>It is common for people to think that they should minimize bias as much as possible even at the expense of variance with the mindset that a presence of bias indicates something basically wrong with their model and algorithm. On the other hand, eventhough a high variance is also not good but a model could at least live with that and predict well on average, at least it is not fundamentally wrong.  </p><p>This kind of logic is wrong. It is true that a high variance and low bias model can preform well in some sort of long-run average sense. However, in real life we are dealing with a single realization of the data set in most cases. In these cases, long run averages are irrelevant, what is important is the one-shot performance of your model on your data and in this case bias and variance are equally important and one should not be improved at an excessive expense to the other.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="3-how-to-reduce-model-variance-bagging-and-resampling"></a>3. How to reduce model variance: Bagging and resampling.<a aria-hidden="true" tabindex="-1" class="hash-link" href="#3-how-to-reduce-model-variance-bagging-and-resampling" title="Direct link to heading">#</a></h4><p>Resampling techniques like Bagging could be used to reduce model variance. In bagging, numerous replicates of the original data set are created using random selection with replacement. Each derivative data set is then used to construct a new model and the models are gathered together into an ensemble. To make a prediction, all of the models in the ensemble are polled and their results are averaged.</p><p>Random Forests is one of the powerful algorithms which is built on Bagging. It works by training numerous decision trees each based on a different resampling of the original training data. In Random Forests the bias of the full model is equivalent to the bias of a single decision tree (which itself has high variance). By creating many of these trees, in effect a &quot;forest&quot;, and then averaging them the variance of the final model can be greatly reduced over that of a single tree. In practice the only limitation on the size of the forest is computing time as an infinite number of trees could be trained without ever increasing bias and with a continual (if asymptotically declining) decrease in the variance.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="shrinkage-method-lasso-vs-ridge"></a>Shrinkage Method: Lasso vs. Ridge<a aria-hidden="true" tabindex="-1" class="hash-link" href="#shrinkage-method-lasso-vs-ridge" title="Direct link to heading">#</a></h2><p><img src="https://i.imgur.com/Yc8ECYg.gif"></p><p>Shrinkage happens when the coefficients decrease towards zero compared to the OLS parameter estimates which is also called regularization. </p><p>In both cases, we are assuming that linear regression with two variables with the mean removed. When we choose different <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Î²</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\beta_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>s and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Î²</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\beta_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>s, we end up with different values for the objective function which is the residual sum of squares (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>S</mi><mi>S</mi></mrow><annotation encoding="application/x-tex">RSS</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span></span></span>). The red contour lines are for the objective function or the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>S</mi><mi>S</mi></mrow><annotation encoding="application/x-tex">RSS</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span></span></span> when different <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span></span></span></span></span>s are used. <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Î²</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\beta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1523199999999998em;vertical-align:-0.19444em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9578799999999998em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span></span></span><span style="top:-3.26344em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.16666em"><span class="mord">^</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em"><span></span></span></span></span></span></span></span></span></span> is the optimal <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span></span></span></span></span> and that yields the minimum <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>S</mi><mi>S</mi></mrow><annotation encoding="application/x-tex">RSS</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span></span></span>. </p><p>For Ridge, we select a <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span></span></span></span></span> that lies within the sphere as <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></msubsup><mo stretchy="false">(</mo><msub><mi>Î²</mi><mi>j</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>&lt;</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">\sum_{i=1}^p (\beta_{j})^2 &lt; c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.113818em;vertical-align:-0.29971000000000003em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em">âˆ‘</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029000000000005em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em"></span><span class="mord mathnormal">c</span></span></span></span></span>. Therefore, mathematically the constraint is the L2 norm which adds up the square of every dimension and taking the sqaure root (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Î²</mi><mn>1</mn><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>Î²</mi><mn>2</mn><mn>2</mn></msubsup><mo>â‰¤</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">\beta_1^2 + \beta_2^2 \leq c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0622159999999998em;vertical-align:-0.24810799999999997em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-2.4518920000000004em;margin-left:-0.05278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.0622159999999998em;vertical-align:-0.24810799999999997em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em"><span style="top:-2.4518920000000004em;margin-left:-0.05278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em"></span><span class="mord mathnormal">c</span></span></span></span></span>). The best <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î²</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em"></span><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span></span></span></span></span> we can get from this constraint is the intersection of the sphere with the contour line.</p><p>On the other hand, the constraint that Lasso assuming that <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>âˆ‘</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></msubsup><mi mathvariant="normal">âˆ£</mi><msub><mi>Î²</mi><mi>j</mi></msub><mi mathvariant="normal">âˆ£</mi><mo>&lt;</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">\sum_{i=1}^p |\beta_{j}| &lt; c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.104002em;vertical-align:-0.29971000000000003em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em">âˆ‘</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029000000000005em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord">âˆ£</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em"><span></span></span></span></span></span></span><span class="mord">âˆ£</span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em"></span><span class="mord mathnormal">c</span></span></span></span></span> has is a diamond. This is considered the L1 norm which is basically adding up the absolute value of every dimension (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">âˆ£</mi><msub><mi>Î²</mi><mn>1</mn></msub><mi mathvariant="normal">âˆ£</mi><mo>+</mo><mi mathvariant="normal">âˆ£</mi><msub><mi>Î²</mi><mn>2</mn></msub><mi mathvariant="normal">âˆ£</mi><mo>â‰¤</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">|\beta_1| + |\beta_2| \leq c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">âˆ£</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">âˆ£</span><span class="mspace" style="margin-right:0.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">âˆ£</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em">Î²</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">âˆ£</span><span class="mspace" style="margin-right:0.2777777777777778em"></span><span class="mrel">â‰¤</span><span class="mspace" style="margin-right:0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em"></span><span class="mord mathnormal">c</span></span></span></span></span>). The ellipse will touch at an axis and this happens when the best intersection sets one coordinate precisely to 0.</p><p>As <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em"></span><span class="mord mathnormal">p</span></span></span></span></span> increases, in Lasso, the multidimensional diamond will have increasing number of corners, and so it is more likely that some coefficients will be set to zero. On the other hand, the coefficients reduce by the same proportion closer to zero but not being set to zero.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2cZh" id="source"></a>Source<a aria-hidden="true" tabindex="-1" class="hash-link" href="#source" title="Direct link to heading">#</a></h2><p><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" target="_blank" rel="noopener noreferrer">Understanding the Bias-Variance Tradeoff</a>  </p><p><a href="https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/" target="_blank" rel="noopener noreferrer">Gentle Introduction to the Bias-Variance Trade-Off in Machine Learning</a> </p><p><a href="https://openreview.net/pdf?id=HkgmzhC5F7" target="_blank" rel="noopener noreferrer">A Modern Take on the Bias-Variance Tradeoff in Neural Networks</a> </p><p><a href="https://www.datasklr.com/extensions-of-ols-regression/regularization-and-shrinkage-ridge-lasso-and-elastic-net-regression" target="_blank" rel="noopener noreferrer">Regularization and Shrinkage: Ridge, Lasso and Elastic Net Regression</a></p></div></article><div class="margin-vert--xl"><div class="row"><div class="col"></div><div class="col text--right"><em><small>Last updated on <time datetime="2020-10-22T00:55:23.000Z" class="docLastUpdatedAt_217_">10/21/2020</time></small></em></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/APM-2020/docs/sec-a/a-04-regularization"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Regularization</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/APM-2020/docs/sec-a/a-06-gradient-descent"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Gradient Descent Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_3SO_"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#course-content" class="table-of-contents__link">Course Content</a></li><li><a href="#bias-variance-trade-off" class="table-of-contents__link">Bias-Variance Trade Off</a><ul><li><a href="#the-bias-variance-decomposition" class="table-of-contents__link">The Bias-Variance Decomposition</a></li><li><a href="#the-bias-variance-tradeoff" class="table-of-contents__link">The Bias-Variance Tradeoff</a></li><li><a href="#how-to-improve-model-performance-managing-bias-and-variance" class="table-of-contents__link">How to Improve Model Performance: Managing Bias and Variance</a></li></ul></li><li><a href="#shrinkage-method-lasso-vs-ridge" class="table-of-contents__link">Shrinkage Method: Lasso vs. Ridge</a></li><li><a href="#source" class="table-of-contents__link">Source</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="text--center"><div>Copyright Â© 2020 Authors. Built with Docusaurus.</div></div></div></footer></div>
<script src="/APM-2020/styles.2cffed3b.js"></script>
<script src="/APM-2020/runtime~main.47f4a8e7.js"></script>
<script src="/APM-2020/main.2d013a91.js"></script>
<script src="/APM-2020/1.1bd411a9.js"></script>
<script src="/APM-2020/2.a2e25927.js"></script>
<script src="/APM-2020/32.9618ee48.js"></script>
<script src="/APM-2020/f976f453.84bb295e.js"></script>
<script src="/APM-2020/17896441.32dbdef4.js"></script>
<script src="/APM-2020/3d264858.47e169e0.js"></script>
</body>
</html>